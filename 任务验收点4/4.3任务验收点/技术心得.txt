Q:在海量数据传输与云端部署中，你遇到了哪些非技术层面的工程瓶颈？
A：a)本地电脑空间不够 百度网盘空间不够 无法使用filezilla上传数据集到远程服务器 因此我做了以下尝试
1 在github找了百度网盘linux命令行工具并部署到远程服务器 但是百度网盘对个人不开放API权限 不把内容转存到自己的云盘就无法上传到远程服务器且对非VIP用户限速极其严重
2 尝试向学长寻找阿里云盘文件链接 因为阿里用户1t免费云空间且限速不严重 AutoDL官方文档也强烈建议使用该网盘 但是学长并没有相关链接
3 尝试在公开数据集寻找替代的数据集 最终选定ImageNet这个1000多类的数据集代替webiNet-5000数据集
b)云端服务器环境极其混乱 由于远程服务器创建虚拟环境和本地anaconda创建虚拟环境并不一样 解决pytorch numpy 和mviT V2模型之间的环境冲突花了很多时间 反复查资料，找镜像 最终解决
c)云端服务器在网站下载任何资源（尤其是在gitee）需要本地cookie 在网络资源的帮助下解决了部分网站资源无法下载的问题

Q:为什么某些参数调整会导致准确率下降？
本次实战中涉及的核心调优参数包括噪声筛选置信度阈值、模型推理批次、图片预处理尺寸、DDP 训练批次 / 学习率等，部分参数调整后出现模型分类准确率、清洗有效性下降，本质是参数与模型特性、数据集分布、训练模式的匹配性被破坏
1. 噪声筛选置信度阈值调优的反向影响
阈值过高（如从 0.2 提升至 0.5）：会过度筛选 “低置信度但有效” 的样本（如 ImageNet 中相似类别样本、拍摄角度特殊的样本），导致训练集有效数据量锐减，模型学不到完整的特征分布，最终分类准确率下降；
阈值过低（如从 0.2 降至 0.05）：会让大量噪声 / 损坏样本残留，污染训练集，模型训练时拟合噪声特征，出现过拟合 + 特征混淆，对测试集的泛化能力大幅降低。
核心本质：置信度阈值是 “噪声筛选精度” 和 “有效样本保留率” 的平衡，偏离数据集固有噪声比例的阈值，会打破这种平衡，直接影响后续训练的数据集质量。
2. 模型相关参数调整的反向影响
预处理尺寸偏离模型设计：MViT V2-Base 原生设计输入尺寸为 224×224，若调整为 112×112，会导致图片特征丢失（如细粒度纹理、类别独有特征），模型推理时无法提取有效判别特征，置信度判断失真，清洗准确率下降；若调整为 448×448，会引发 GPU 显存溢出，被迫降低批次，导致特征提取不充分，同时增加冗余计算。
DDP 训练学习率 / 批次不合理：① 学习率过高（如从 1e-4 提升至 1e-2），会导致模型在训练中跳过最优解，权重更新震荡，无法收敛，准确率持续波动下降；② 批次过大（如从 16 提升至 64），在单卡 4090 环境下会导致显存不足，被迫使用梯度累积，破坏 DDP 分布式训练的梯度同步节奏，批次归一化效果变差，特征分布拟合不精准；③ 批次过小（如从 16 降至 4），会导致每个 step 的梯度方差过大，模型训练不稳定，收敛速度慢且准确率偏低。
3. 数据集遍历参数调整的反向影响
本次实战中设置max_cls=50、max_imgs_per_cls=20以快速出结果，若盲目扩大max_cls但未同步调整模型推理缓存，会导致模型在遍历多类别时出现特征缓存溢出，类别间特征混淆，清洗时对相似类别的判别准确率下降；若无限制增加max_imgs_per_cls，会导致单批次处理数据量过大，GPU 内存占满后触发数据交换，推理速度骤降且特征提取出错率升高。
4.单一参数的调整需兼顾模型固有特性 （如 MViT V2 的视觉 Transformer 架构对输入尺寸、特征序列长度的敏感）、数据集分布（如 ImageNet 的 1000 类均衡分布、百万级样本的噪声比例）、硬件 / 训练模式约束（如单卡 4090 的显存、DDP 分布式训练的梯度同步规则），脱离整体匹配的单一参数调优，必然导致准确率、效率等指标的下降。

Q:目前的数据清洗算法在处理长尾分布数据时有何局限？
基于MVit-V2模型的数据清洗  主要依靠ai编写data cleaner函数 面向ai编程（bushi）跟着李沐等 名师了解了基本原理  对这一过程有了定性认知
1. 小众类别样本被误筛
当前清洗算法的核心是依赖预训练模型的类别判别能力，而 MViT V2 模型均在 ImageNet 等均衡数据集上预训练，模型对高频大类的特征提取和判别能力极强，但对长尾小众类的特征学习不充分（预训练中见得少）。在长尾分布数据清洗中，模型对小众类别样本的推理置信度天然偏低，即使样本是有效无噪声的，也会因置信度低于阈值被判定为 “噪声” 而筛除，最终导致小众类别样本进一步流失，长尾分布更严重，后续模型训练时对小众类的识别准确率几乎为 0。
2. 单一置信度阈值无法适配长尾分布的类别差异
本次实战采用全局统一的置信度阈值（0.2） 筛选噪声，该方式在均衡数据中有效，但在长尾数据中存在致命缺陷：
高频大类：样本量充足，模型判别精准，统一阈值能有效筛除真正的噪声；
小众类别：样本量少，模型判别置信度整体偏低，统一阈值会将大量有效小众样本误判为噪声，同时可能因模型对小众类噪声的特征识别能力弱，导致小众类噪声残留。
即 “统一阈值” 无法兼顾长尾数据中不同类别、不同样本量的判别特性，陷入 “筛除有效小众样本” 或 “保留小众类噪声” 的两难。
3. 算法未考虑长尾数据的 “样本分布特性”，清洗有效性失衡
当前清洗算法仅以单样本置信度为唯一筛选依据，未考虑样本的类别内分布和类别间相似度：
长尾小众类的样本本身分布集中（样本量少，特征多样性低），若因置信度低被筛除部分样本，会导致类别内特征分布断裂，模型后续无法学习到完整的小众类特征；
部分长尾小众类与高频大类存在较高的特征相似度（如 ImageNet 中 “小众鸟类” 与 “高频鸟类”），模型易将小众类样本判定为大类样本，置信度偏低，最终被误筛，加剧类别间的特征混淆。